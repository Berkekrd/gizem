{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-12-06T22:29:32.136774Z","iopub.status.busy":"2023-12-06T22:29:32.136351Z","iopub.status.idle":"2023-12-06T22:30:47.677532Z","shell.execute_reply":"2023-12-06T22:30:47.673906Z","shell.execute_reply.started":"2023-12-06T22:29:32.136742Z"},"trusted":true},"outputs":[],"source":["pip install --upgrade tensorflow tensorflow-io"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-12-06T22:30:59.569458Z","iopub.status.busy":"2023-12-06T22:30:59.567577Z","iopub.status.idle":"2023-12-06T22:30:59.598208Z","shell.execute_reply":"2023-12-06T22:30:59.594083Z","shell.execute_reply.started":"2023-12-06T22:30:59.569338Z"},"trusted":true},"outputs":[],"source":["# General Imports\n","import tensorflow as tf\n","import pandas as pd\n","import numpy as np\n","import random\n","import os\n","\n","# Visualization\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Building Model\n","from keras.utils import plot_model\n","from tensorflow.keras import models\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Conv2D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten\n","from tensorflow.keras.optimizers import legacy\n","\n","# Training Model\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ReduceLROnPlateau\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","# Data Processing\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import img_to_array\n","from tensorflow.keras.preprocessing.image import array_to_img\n","from tensorflow.keras.preprocessing.image import load_img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:31:10.284337Z","iopub.status.busy":"2023-12-06T22:31:10.282713Z","iopub.status.idle":"2023-12-06T22:31:10.298624Z","shell.execute_reply":"2023-12-06T22:31:10.296996Z","shell.execute_reply.started":"2023-12-06T22:31:10.284288Z"},"trusted":true},"outputs":[],"source":["# Global variables\n","SAVE = False\n","SEED = 111\n","\n","# Setting seed for consistent results\n","tf.keras.utils.set_random_seed(SEED)\n","tf.random.set_seed(SEED)\n","np.random.seed(SEED)\n","\n","# Data Visualization updates\n","%config InlineBackend.figure_format = 'retina'\n","plt.rcParams[\"figure.figsize\"] = (16, 10)\n","plt.rcParams.update({'font.size': 14})\n","\n","# Data Classifications\n","CLASS_TYPES = ['pituitary', 'notumor', 'meningioma', 'glioma']\n","N_TYPES = len(CLASS_TYPES)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-12-06T22:31:11.485113Z","iopub.status.busy":"2023-12-06T22:31:11.484679Z","iopub.status.idle":"2023-12-06T22:31:11.497358Z","shell.execute_reply":"2023-12-06T22:31:11.495748Z","shell.execute_reply.started":"2023-12-06T22:31:11.485082Z"},"trusted":true},"outputs":[],"source":["# Function for inporting data           \n","def get_data_labels(directory, shuffle=True, random_state=0):\n","    \"\"\"\n","    Function used for going into the main training directory\n","    whose directory has sub-class-types.\n","    \"\"\"\n","    from sklearn.utils import shuffle\n","    import os\n","\n","    # Lists to store data and labels\n","    data_path = []\n","    data_labels = []\n","    \n","    for label in os.listdir(directory):\n","        label_dir = os.path.join(directory, label)\n","\n","        # Avoid MacOS storing path\n","        if not os.path.isdir(label_dir):\n","            continue\n","\n","        # Going into each folder and getting image path\n","        for image in os.listdir(label_dir):\n","            image_path = os.path.join(label_dir, image)\n","            data_path.append(image_path)\n","            data_labels.append(label)\n","            \n","    if shuffle:\n","        data_path, data_labels = shuffle(data_path, data_labels, random_state=random_state)\n","            \n","    return data_path, data_labels\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:31:12.058201Z","iopub.status.busy":"2023-12-06T22:31:12.057178Z","iopub.status.idle":"2023-12-06T22:31:13.7854Z","shell.execute_reply":"2023-12-06T22:31:13.784085Z","shell.execute_reply.started":"2023-12-06T22:31:12.058155Z"},"trusted":true},"outputs":[],"source":["# Setting up file paths for training and testing\n","USER_PATH = r\"/input/brain-tumor-mri-dataset\"\n","train_dir = USER_PATH + r'/Training/'\n","test_dir = USER_PATH + r'/Testing/'\n","\n","# Getting data using above function\n","train_paths, train_labels = get_data_labels(train_dir)\n","test_paths, test_labels = get_data_labels(test_dir)\n","\n","# Printing traing and testing sample sizes\n","print('Training')\n","print(f'Number of Paths: {len(train_paths)}')\n","print(f'Number of Labels: {len(train_labels)}')\n","print('\\nTesting')\n","print(f'Number of Paths: {len(test_paths)}')\n","print(f'Number of Labels: {len(test_labels)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-06T22:31:14.878505Z","iopub.status.busy":"2023-12-06T22:31:14.878118Z","iopub.status.idle":"2023-12-06T22:31:15.829337Z","shell.execute_reply":"2023-12-06T22:31:15.828537Z","shell.execute_reply.started":"2023-12-06T22:31:14.878474Z"},"trusted":true},"outputs":[],"source":["_, ax = plt.subplots(ncols=3, figsize=(20, 14))\n","\n","# Plotting training data types\n","class_counts = [len([x for x in train_labels if x == label]) for label in CLASS_TYPES]\n","print('Training Counts')\n","print(dict(zip(CLASS_TYPES, class_counts)))\n","\n","ax[0].set_title('Training Data')\n","ax[0].pie(\n","    class_counts,\n","    labels=[label.title() for label in CLASS_TYPES],\n","    colors=['#FAC500','#0BFA00', '#0066FA','#FA0000'], \n","    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n","    explode=tuple(0.01 for i in range(N_TYPES)),\n","    textprops={'fontsize': 20}\n",")\n","\n","# Plotting distribution of train test split\n","ax[1].set_title('Train Test Split')\n","ax[1].pie(\n","    [len(train_labels), len(test_labels)],\n","    labels=['Train','Test'],\n","    colors=['darkcyan', 'orange'], \n","    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum([len(train_labels), len(test_labels)]) / 100),\n","    explode=(0.1, 0),\n","    startangle=85,\n","    textprops={'fontsize': 20}\n",")\n","\n","# Plotting testing data types\n","class_counts = [len([x for x in test_labels if x == label]) for label in CLASS_TYPES]\n","print('\\nTesting Counts')\n","print(dict(zip(CLASS_TYPES, class_counts)))\n","\n","ax[2].set_title('Testing Data')\n","ax[2].pie(\n","    class_counts,\n","    labels=[label.title() for label in CLASS_TYPES],\n","    colors=['#FAC500', '#0BFA00', '#0066FA', '#FA0000'],\n","    autopct=lambda p: '{:.2f}%\\n{:,.0f}'.format(p, p * sum(class_counts) / 100),\n","    explode=tuple(0.01 for i in range(N_TYPES)),  # Explode the slices slightly for better visualization\n","    textprops={'fontsize': 20}  # Set the font size for the text on the pie chart\n",")\n","\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:31:27.662511Z","iopub.status.busy":"2023-12-06T22:31:27.662083Z","iopub.status.idle":"2023-12-06T22:31:27.704244Z","shell.execute_reply":"2023-12-06T22:31:27.702811Z","shell.execute_reply.started":"2023-12-06T22:31:27.662465Z"},"trusted":true},"outputs":[],"source":["# getting image to test output\n","im = load_img(train_paths[3], target_size=(150, 150))\n","im = img_to_array(im)\n","\n","# Reshape it to (1, 150, 150, 3)\n","im = np.expand_dims(im, axis=0)\n","print(f'x reshaped: {im.shape}')\n","\n","# normilzation tensor\n","im /= np.max(im) # ~ np.max(img_tensor)\n","\n","# Convert the array back to the image format\n","im = array_to_img(im[0])\n","display(im)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-12-06T22:31:29.103797Z","iopub.status.busy":"2023-12-06T22:31:29.103393Z","iopub.status.idle":"2023-12-06T22:31:29.114178Z","shell.execute_reply":"2023-12-06T22:31:29.112579Z","shell.execute_reply.started":"2023-12-06T22:31:29.103765Z"},"trusted":true},"outputs":[],"source":["# Function to display a list of images based on the given index\n","def show_images(paths, label_paths, index_list=range(10), im_size=250, figsize=(12, 8), save=False):\n","    \"\"\"\n","    Show images from a given path based on the inputted\n","    list indices related to the desired images one wishes\n","    to see.\n","    \"\"\"\n","\n","    num_images = len(index_list)\n","    num_rows = (num_images + 3) // 4\n","    \n","    _, ax = plt.subplots(nrows=num_rows, ncols=4, figsize=figsize)\n","    ax = ax.flatten()\n","\n","    for i, index in enumerate(index_list):\n","        if i >= num_images:\n","            break\n","        \n","        image = load_img(paths[index], target_size=(im_size, im_size))\n","        ax[i].imshow(image)\n","        ax[i].set_title(f'{index}: {label_paths[index]}')\n","        ax[i].axis('off')\n","\n","    plt.tight_layout()\n","    \n","    if save:\n","        plt.savefig('show_image.pdf')\n","    else:\n","        plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:39.389883Z","iopub.status.busy":"2023-12-06T22:51:39.389438Z","iopub.status.idle":"2023-12-06T22:51:42.515646Z","shell.execute_reply":"2023-12-06T22:51:42.514671Z","shell.execute_reply.started":"2023-12-06T22:51:39.389849Z"},"trusted":true},"outputs":[],"source":["# Four different data classification images, from three different angles (images are independent)\n","show_images(train_paths, train_labels, im_size=350, figsize=(13,10),\n","            index_list=[0, 94, 235, 17,\n","                        61, 324, 55, 45,\n","                        374, 65, 391, 488])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:51.528397Z","iopub.status.busy":"2023-12-06T22:51:51.527934Z","iopub.status.idle":"2023-12-06T22:51:51.534216Z","shell.execute_reply":"2023-12-06T22:51:51.532947Z","shell.execute_reply.started":"2023-12-06T22:51:51.528362Z"},"trusted":true},"outputs":[],"source":["# Image size\n","image_size = (150, 150)\n","\n","# Training batch size\n","batch_size = 32"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:51.953901Z","iopub.status.busy":"2023-12-06T22:51:51.953461Z","iopub.status.idle":"2023-12-06T22:51:57.99092Z","shell.execute_reply":"2023-12-06T22:51:57.989987Z","shell.execute_reply.started":"2023-12-06T22:51:51.953865Z"},"trusted":true},"outputs":[],"source":["# Data augmentation and preprocessing\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=10,\n","                                   brightness_range=(0.85, 1.15),\n","                                   width_shift_range=0.002,\n","                                   height_shift_range=0.002,\n","                                   shear_range=12.5,\n","                                   zoom_range=0,\n","                                   horizontal_flip=True,\n","                                   vertical_flip=False,\n","                                   fill_mode=\"nearest\")\n","\n","\n","# applying the generator to training data with constant seed\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=image_size,\n","                                                    batch_size=batch_size,\n","                                                    class_mode=\"categorical\",\n","                                                    seed=SEED)\n","\n","# No augmentation of the test data, just rescaling\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# applying the generator to testing data with constant seed\n","test_generator = test_datagen.flow_from_directory(test_dir,\n","                                                  target_size=image_size,\n","                                                  batch_size=batch_size,\n","                                                  class_mode=\"categorical\",\n","                                                  shuffle=False,\n","                                                  seed=SEED)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:57.994195Z","iopub.status.busy":"2023-12-06T22:51:57.993169Z","iopub.status.idle":"2023-12-06T22:51:58.001483Z","shell.execute_reply":"2023-12-06T22:51:57.999977Z","shell.execute_reply.started":"2023-12-06T22:51:57.994157Z"},"trusted":true},"outputs":[],"source":["# Accessing class indices for training data generator\n","class_indices_train = train_generator.class_indices\n","class_indices_train_list = list(train_generator.class_indices.keys())\n","\n","\n","# Displaying categorical types\n","print(\"Categorical types for the training data:\")\n","print(class_indices_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.execute_input":"2023-12-06T22:51:58.004168Z","iopub.status.busy":"2023-12-06T22:51:58.003695Z","iopub.status.idle":"2023-12-06T22:51:58.014686Z","shell.execute_reply":"2023-12-06T22:51:58.013599Z","shell.execute_reply.started":"2023-12-06T22:51:58.004134Z"},"trusted":true},"outputs":[],"source":["def show_ImageDataGenerator(ImageDataGenerator, num_samples=5, figsize=(12, 12), save=False):\n","    \"\"\"\n","    Function to viusalize how the ImageDataGenerator augments the data\n","    \"\"\"\n","    \n","    # Generate augmented samples\n","    augmented_samples = train_generator.next()\n","\n","    # Extract images from the batch\n","    images = augmented_samples[0][:num_samples]\n","\n","    # Display the augmented images\n","    fig, axes = plt.subplots(1, num_samples, figsize=figsize)\n","    \n","    for i, ax in enumerate(axes):\n","        ax.imshow(images[i])\n","        ax.axis('off')\n","        \n","    plt.tight_layout()\n","        \n","    if save:\n","        plt.savefig('show_ImageDataGenerator.pdf')\n","        \n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:58.017703Z","iopub.status.busy":"2023-12-06T22:51:58.016991Z","iopub.status.idle":"2023-12-06T22:51:59.353835Z","shell.execute_reply":"2023-12-06T22:51:59.352432Z","shell.execute_reply.started":"2023-12-06T22:51:58.017667Z"},"trusted":true},"outputs":[],"source":["show_ImageDataGenerator(train_datagen, num_samples=5, figsize=(12.5, 8), save=SAVE)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:51:59.355904Z","iopub.status.busy":"2023-12-06T22:51:59.355397Z","iopub.status.idle":"2023-12-06T22:51:59.366428Z","shell.execute_reply":"2023-12-06T22:51:59.364825Z","shell.execute_reply.started":"2023-12-06T22:51:59.355852Z"},"trusted":true},"outputs":[],"source":["# Image shape: height, width, RBG\n","image_shape = (image_size[0], image_size[1], 3)\n","\n","# Training epochs\n","epochs = 40\n","\n","# Steps per epoch\n","steps_per_epoch = train_generator.samples // batch_size\n","\n","# Validation steps\n","validation_steps = test_generator.samples // batch_size\n","\n","print(f'Image shape: {image_shape}')\n","print(f'Epochs: {epochs}')\n","print(f'Batch size: {batch_size}')\n","print(f'Steps Per Epoch: {steps_per_epoch}')\n","print(f'Validation steps: {validation_steps}')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-12-06T22:52:02.801622Z","iopub.status.busy":"2023-12-06T22:52:02.801166Z","iopub.status.idle":"2023-12-06T22:52:02.820819Z","shell.execute_reply":"2023-12-06T22:52:02.819602Z","shell.execute_reply.started":"2023-12-06T22:52:02.801588Z"},"trusted":true},"outputs":[],"source":["def plot_sample_predictions(model, test_generator, categories, test_dir, num_samples=9, figsize=(12, 8)):\n","    \"\"\"\n","    Nice display of prediction samples to see CNN predictions\n","    for classification.\n","    \"\"\"\n","    # Make predictions on the test dataset\n","    predictions = model.predict(test_generator)\n","    predicted_categories = np.argmax(predictions, axis=1)\n","    true_categories = test_generator.classes\n","\n","    # Randomly sample test images\n","    test_images = np.array(test_generator.filepaths)\n","    sample_indices = np.random.choice(len(test_images), size=num_samples, replace=False)\n","    sample_images = test_images[sample_indices]\n","    sample_predictions = [categories[predicted_categories[i]] for i in sample_indices]\n","    sample_true_labels = [categories[true_categories[i]] for i in sample_indices]\n","\n","    # Plot sample images with their predicted and true labels\n","    plt.figure(figsize=figsize)\n","    \n","    # Loop over samples\n","    for i, image_path in enumerate(sample_images):\n","        # Form subplot and plot\n","        plt.subplot(3, 3, i + 1)\n","        img = plt.imread(image_path)\n","        plt.imshow(img)\n","        plt.axis(\"off\")\n","        \n","        # Set axis label color depending on correct prediction or not\n","        prediction_color = 'green' if sample_predictions[i] == sample_true_labels[i] else 'red'\n","        plt.title(f\"Predicted: {sample_predictions[i]}\\nTrue: {sample_true_labels[i]}\", color=prediction_color)\n","        \n","    plt.tight_layout()\n","    plt.show()\n","\n","    \n","def CM(CNN_model, test_generator, categories):\n","    \"\"\"\n","    Function to return the confusion matrix of a given CNN model.\n","    \"\"\"\n","    from sklearn.metrics import confusion_matrix\n","    # Predictions on test dataset\n","    predictions = CNN_model.predict(test_generator)\n","    predicted_categories = np.argmax(predictions, axis=1)\n","    true_categories = test_generator.classes\n","\n","    # Create a confusion matrix\n","    confusion_matrix_array = confusion_matrix(true_categories, predicted_categories)\n","    \n","    return confusion_matrix_array\n","\n","\n","def calculate_metrics(confusion_matrix, categories):\n","    \"\"\"\n","    Function to calculate important metrics for multi-classification problems.\n","    \"\"\"\n","    # Calculating 4 different metrics\n","    precision = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis=0)\n","    recall = np.diag(confusion_matrix) / np.sum(confusion_matrix, axis=1)\n","    f1_score = 2 * (precision * recall) / (precision + recall)\n","    accuracy = np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n","\n","    # Printing the results based on each category\n","    for i, category in enumerate(categories):\n","        print(f\"Class: {category.title()}\")\n","        print(f\"Precision: {precision[i]:.3f}\")\n","        print(f\"Recall: {recall[i]:.3f}\")\n","        print(f\"F1-Score: {f1_score[i]:.3f}\\n\")\n","        \n","    # Showing the total accuracy of the model\n","    print(f\"\\nAccuracy: {accuracy:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:54:17.711085Z","iopub.status.busy":"2023-12-06T22:54:17.710607Z","iopub.status.idle":"2023-12-06T22:54:17.892812Z","shell.execute_reply":"2023-12-06T22:54:17.891527Z","shell.execute_reply.started":"2023-12-06T22:54:17.711048Z"},"trusted":true},"outputs":[],"source":["# Define the model architecture\n","model = models.Sequential([\n","    \n","    # Convolutional layer 1\n","    Conv2D(32, (4, 4), activation=\"relu\", input_shape=image_shape),\n","    MaxPooling2D(pool_size=(3, 3)),\n","\n","    # Convolutional layer 2\n","    Conv2D(64, (4, 4), activation=\"relu\"),\n","    MaxPooling2D(pool_size=(3, 3)),\n","\n","    # Convolutional layer 3\n","    Conv2D(128, (4, 4), activation=\"relu\"),\n","    MaxPooling2D(pool_size=(3, 3)),\n","\n","    # Convolutional layer 4\n","    Conv2D(128, (4, 4), activation=\"relu\"),\n","    Flatten(),\n","\n","    # Full connect layers\n","    Dense(512, activation=\"relu\"),\n","    Dropout(0.5, seed=SEED),\n","    Dense(N_TYPES, activation=\"softmax\")\n","])\n","\n","model.summary()\n","\n","optimizer = legacy.Adam(learning_rate=0.001, beta_1=0.869, beta_2=0.995)\n","model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-12-06T22:54:20.639446Z","iopub.status.busy":"2023-12-06T22:54:20.638991Z","iopub.status.idle":"2023-12-06T22:54:35.344292Z","shell.execute_reply":"2023-12-06T22:54:35.343078Z","shell.execute_reply.started":"2023-12-06T22:54:20.639412Z"},"trusted":true},"outputs":[],"source":["!pip install visualkeras"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:54:54.480375Z","iopub.status.busy":"2023-12-06T22:54:54.479906Z","iopub.status.idle":"2023-12-06T22:54:54.516179Z","shell.execute_reply":"2023-12-06T22:54:54.514871Z","shell.execute_reply.started":"2023-12-06T22:54:54.480337Z"},"trusted":true},"outputs":[],"source":["from visualkeras import layered_view\n","\n","# Visualize the model\n","layered_view(model, legend=True, max_xy=300)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-06T22:55:03.140786Z","iopub.status.busy":"2023-12-06T22:55:03.14036Z","iopub.status.idle":"2023-12-06T22:55:03.506433Z","shell.execute_reply":"2023-12-06T22:55:03.505078Z","shell.execute_reply.started":"2023-12-06T22:55:03.140754Z"},"trusted":true},"outputs":[],"source":["model_visual = models.Model(inputs=model.input, outputs=model.output)\n","\n","# Save model architecture to a file\n","plot_model(model_visual, show_dtype=True, to_file='model_architecture.png', show_shapes=True)\n","\n","# Display model architecture in the notebook\n","\n","from IPython.display import Image\n","Image(retina=True, filename='model_architecture.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-12-06T22:55:06.495803Z","iopub.status.busy":"2023-12-06T22:55:06.495383Z"},"trusted":true},"outputs":[],"source":["# Stop training if loss doesn't keep decreasing.\n","model_es = EarlyStopping(monitor='loss', min_delta=1e-9, patience=8, verbose=True)\n","model_rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose=True)\n","\n","# Training the model\n","history = model.fit(train_generator,\n","                    steps_per_epoch=steps_per_epoch,\n","                    epochs=epochs,\n","                    validation_data=test_generator,\n","                    validation_steps=validation_steps,\n","                    callbacks=[model_es, model_rlr])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:12:56.580509Z","iopub.status.busy":"2023-07-28T12:12:56.58001Z","iopub.status.idle":"2023-07-28T12:13:06.96152Z","shell.execute_reply":"2023-07-28T12:13:06.960262Z","shell.execute_reply.started":"2023-07-28T12:12:56.580469Z"},"trusted":true},"outputs":[],"source":["# Evaluating the model\n","loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples//batch_size)\n","print(f\"Test Loss: {loss:0.5f}\")\n","print(f\"Test Accuracy: {accuracy:0.5f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:13:06.963639Z","iopub.status.busy":"2023-07-28T12:13:06.96304Z","iopub.status.idle":"2023-07-28T12:13:07.843631Z","shell.execute_reply":"2023-07-28T12:13:07.842354Z","shell.execute_reply.started":"2023-07-28T12:13:06.963604Z"},"trusted":true},"outputs":[],"source":["_, ax = plt.subplots(ncols=2, figsize=(15, 6))\n","\n","# Plot the training and validation accuracy over epochs\n","ax[0].plot(history.history['accuracy'])\n","ax[0].plot(history.history['val_accuracy'])\n","ax[0].set_title('Model 2 Accuracy')\n","ax[0].set_xlabel('Epoch')\n","ax[0].set_ylabel('Accuracy')\n","ax[0].legend(['Train', 'Validation'])\n","ax[0].grid(alpha=0.2)\n","\n","# Plot the training and validation loss over epochs\n","ax[1].plot(history.history['loss'])\n","ax[1].plot(history.history['val_loss'])\n","ax[1].set_title('Model 2 Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].set_ylabel('Loss')\n","ax[1].legend(['Train', 'Validation'])\n","ax[1].grid(alpha=0.2)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:13:07.845786Z","iopub.status.busy":"2023-07-28T12:13:07.845263Z","iopub.status.idle":"2023-07-28T12:13:18.688229Z","shell.execute_reply":"2023-07-28T12:13:18.687013Z","shell.execute_reply.started":"2023-07-28T12:13:07.845749Z"},"trusted":true},"outputs":[],"source":["# Plotting confusion matrix\n","confusion_matrix = CM(CNN_model=model, test_generator=test_generator, categories=class_indices_train_list)\n","\n","plt.figure(figsize=(8,8))\n","sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"True\")\n","plt.xticks(ticks=np.arange(N_TYPES) + 0.5,\n","           labels=[name.title() for name in class_indices_train_list], ha='center')\n","plt.yticks(ticks=np.arange(N_TYPES) + 0.5, \n","           labels=[name.title() for name in class_indices_train_list], va='center')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:12:27.201464Z","iopub.status.busy":"2023-07-28T12:12:27.200964Z","iopub.status.idle":"2023-07-28T12:12:27.208199Z","shell.execute_reply":"2023-07-28T12:12:27.207229Z","shell.execute_reply.started":"2023-07-28T12:12:27.201429Z"},"trusted":true},"outputs":[],"source":["# Showing metrics\n","calculate_metrics(confusion_matrix, categories=class_indices_train_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:12:27.210302Z","iopub.status.busy":"2023-07-28T12:12:27.209653Z","iopub.status.idle":"2023-07-28T12:12:38.096491Z","shell.execute_reply":"2023-07-28T12:12:38.095376Z","shell.execute_reply.started":"2023-07-28T12:12:27.210266Z"},"trusted":true},"outputs":[],"source":["# Using functions in 6.1 for showing results\n","plot_sample_predictions(model=model, \n","                        test_generator=test_generator, \n","                        categories=class_indices_train_list,\n","                        test_dir=test_dir, \n","                        num_samples=9,\n","                        figsize=(13, 12))"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-28T12:13:23.216265Z","iopub.status.busy":"2023-07-28T12:13:23.214816Z","iopub.status.idle":"2023-07-28T12:13:23.233089Z","shell.execute_reply":"2023-07-28T12:13:23.231601Z","shell.execute_reply.started":"2023-07-28T12:13:23.216221Z"},"trusted":true},"outputs":[],"source":["# channnel map plot\n","def plot_channel_activation_maps(model, image, images_per_row=16, N=8, save=False):\n","    \"\"\"\n","    Function to visualize how the first N layers of the model observe the input image.\n","\n","    Parameters:\n","        model (tensorflow.keras.models.Model): The Keras model for which to visualize the activation maps.\n","        image (numpy.ndarray): The input image for which to generate activation maps.\n","        images_per_row (int): Number of activation maps to display per row in the grid.\n","        N (int): Number of layers to visualize.\n","        save (bool): If True, save the plots as PDF files.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    from tensorflow.keras.models import Model\n","    \n","    # Create a sub-model that outputs activations for the first N layers\n","    activation_model = Model(inputs=model.input, outputs=[layer.output for layer in model.layers[:N]])\n","    activations = activation_model.predict(image)\n","\n","    # Get the names of the layers for labeling the plots\n","    layer_names = [layer.name for layer in model.layers[:N]]\n","\n","    # Visualize the feature maps for each layer\n","    for layer_name, layer_activation in zip(layer_names, activations):\n","        # This is the number of features in the feature map\n","        n_features = layer_activation.shape[-1]\n","        # The feature map has shape (1, size, size, n_features)\n","        size = layer_activation.shape[1]\n","        # We will tile the activation channels in this matrix\n","        n_cols = n_features // images_per_row\n","        display_grid = np.zeros((size * n_cols, images_per_row * size))\n","\n","        # We'll tile each filter into this big horizontal grid\n","        for col in range(n_cols):\n","            for row in range(images_per_row):\n","                channel_image = layer_activation[0, :, :, col * images_per_row + row]\n","                # Post-process the feature to make it visually palatable\n","                channel_image -= channel_image.mean()\n","                epsilon = 1e-8  # A small epsilon value to avoid division by zero\n","                channel_std = channel_image.std() + epsilon\n","                channel_image /= channel_std\n","                channel_image *= 64\n","                channel_image += 128\n","                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n","                display_grid[col * size: (col + 1) * size,\n","                             row * size: (row + 1) * size] = channel_image\n","\n","        # Display the grid\n","        scale = 1. / size\n","        plt.figure(figsize=(scale * display_grid.shape[1],\n","                            scale * display_grid.shape[0]))\n","        plt.title(layer_name)\n","        plt.grid(False)\n","        plt.axis('off')\n","        plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","\n","        if save:\n","            plt.savefig(f'plot_channel_activation_maps_{layer_name}.pdf')\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:13:23.489692Z","iopub.status.busy":"2023-07-28T12:13:23.489113Z","iopub.status.idle":"2023-07-28T12:13:23.602698Z","shell.execute_reply":"2023-07-28T12:13:23.601478Z","shell.execute_reply.started":"2023-07-28T12:13:23.489649Z"},"trusted":true},"outputs":[],"source":["# Get the next batch from the test generator\n","batch_images, batch_labels = next(test_generator)\n","\n","# Extract the first image from the batch\n","image, label = batch_images[0], batch_labels[0]\n","image_tensor = np.expand_dims(image, axis=0)\n","\n","# Get the class indices from the test generator\n","class_indices = test_generator.class_indices\n","\n","# Convert the one-hot encoded label to the class name\n","label_name = [k for k, v in class_indices.items() if np.argmax(label) == v][0]\n","\n","# Display the class name\n","print(f\"Class name of the first image: {label_name}\")\n","print(f'Shape {image_tensor.shape}')\n","array_to_img(image_tensor[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:13:24.661837Z","iopub.status.busy":"2023-07-28T12:13:24.660745Z","iopub.status.idle":"2023-07-28T12:13:27.287978Z","shell.execute_reply":"2023-07-28T12:13:27.286748Z","shell.execute_reply.started":"2023-07-28T12:13:24.661772Z"},"trusted":true},"outputs":[],"source":["plot_channel_activation_maps(model=model, image=image_tensor, N=5, save=SAVE)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2023-07-28T12:13:29.409965Z","iopub.status.busy":"2023-07-28T12:13:29.409105Z","iopub.status.idle":"2023-07-28T12:13:29.422653Z","shell.execute_reply":"2023-07-28T12:13:29.421591Z","shell.execute_reply.started":"2023-07-28T12:13:29.409917Z"},"trusted":true},"outputs":[],"source":["# Visualization of mis-classsified images\n","def visualize_misclassified_images(model, test_generator, class_indices):\n","    \"\"\"\n","    Visualize misclassified images from the test set alongside their predicted and true labels.\n","\n","    Parameters:\n","        model (tensorflow.keras.models.Model): The trained Keras model.\n","        test_generator (tensorflow.keras.preprocessing.image.DirectoryIterator): The test data generator.\n","        class_indices (dict): Dictionary mapping class names to their corresponding integer labels.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    \n","    from tensorflow.keras.preprocessing.image import array_to_img\n","    \n","    misclassified_images = []\n","    misclassified_labels_true = []\n","    misclassified_labels_pred = []\n","\n","    for i in range(len(test_generator)):\n","        batch_images, batch_labels = next(test_generator)\n","        batch_predictions = model.predict(batch_images, verbose=False)\n","        predicted_labels = [list(class_indices.keys())[np.argmax(pred)] for pred in batch_predictions]\n","        true_labels = [list(class_indices.keys())[np.argmax(label)] for label in batch_labels]\n","\n","        for j in range(len(batch_images)):\n","            if predicted_labels[j] != true_labels[j]:\n","                misclassified_images.append(batch_images[j])\n","                misclassified_labels_true.append(true_labels[j])\n","                misclassified_labels_pred.append(predicted_labels[j])\n","\n","    # Display misclassified images alongside their true and predicted labels\n","    num_misclassified = len(misclassified_images)\n","    num_rows = int(np.ceil(num_misclassified / 4))\n","    plt.figure(figsize=(12, 3 * num_rows))\n","\n","    for i in range(num_misclassified):\n","        plt.subplot(num_rows, 4, i + 1)\n","        plt.title(f\"True: {misclassified_labels_true[i]}\\nPred: {misclassified_labels_pred[i]}\", color='red')\n","        plt.imshow(array_to_img(misclassified_images[i]))\n","        plt.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-28T12:13:29.626235Z","iopub.status.busy":"2023-07-28T12:13:29.623402Z","iopub.status.idle":"2023-07-28T12:13:43.692466Z","shell.execute_reply":"2023-07-28T12:13:43.691097Z","shell.execute_reply.started":"2023-07-28T12:13:29.626189Z"},"trusted":true},"outputs":[],"source":["# Using function above \n","visualize_misclassified_images(model, test_generator, test_generator.class_indices)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":1608934,"sourceId":2645886,"sourceType":"datasetVersion"}],"dockerImageVersionId":30527,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
