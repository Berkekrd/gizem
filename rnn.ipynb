{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2645886,"sourceType":"datasetVersion","datasetId":1608934},{"sourceId":6826002,"sourceType":"datasetVersion","datasetId":3925128}],"dockerImageVersionId":30559,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport gc\nfrom tensorflow.keras.layers import AveragePooling2D\nfrom tensorflow.keras.layers import Dropout, GlobalAveragePooling2D, Activation, BatchNormalization, Dropout, LSTM, ConvLSTM2D\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.layers import Input,Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation, LSTM, ConvLSTM2D, Lambda, Reshape, BatchNormalization, Bidirectional\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint,TensorBoard,TerminateOnNaN, LearningRateScheduler, CSVLogger\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\nfrom tensorflow.keras.layers import Lambda, Reshape, DepthwiseConv2D, ZeroPadding2D, Add, MaxPooling2D,Activation, Flatten, Conv2D, Dense, Input, Dropout, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, roc_auc_score, roc_curve, auc\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom keras.applications import imagenet_utils\nfrom tensorflow.keras import layers\n!pip install tensorflow-addons\nimport tensorflow_addons as tfa\nimport pandas as pd\nimport numpy as np\nimport random\nimport keras\nimport shutil\nimport pathlib\nimport itertools\nimport cv2\nimport os\nimport matplotlib.image as mpimg\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:11.309446Z","iopub.execute_input":"2023-10-29T14:54:11.309836Z","iopub.status.idle":"2023-10-29T14:54:53.114167Z","shell.execute_reply.started":"2023-10-29T14:54:11.309804Z","shell.execute_reply":"2023-10-29T14:54:53.113268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training/'\ntest_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing/'","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:53.116369Z","iopub.execute_input":"2023-10-29T14:54:53.117349Z","iopub.status.idle":"2023-10-29T14:54:53.121877Z","shell.execute_reply.started":"2023-10-29T14:54:53.117314Z","shell.execute_reply":"2023-10-29T14:54:53.120593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirpath, dirnames, filenames in os.walk(train_dir):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:53.123275Z","iopub.execute_input":"2023-10-29T14:54:53.123498Z","iopub.status.idle":"2023-10-29T14:54:57.6827Z","shell.execute_reply.started":"2023-10-29T14:54:53.123478Z","shell.execute_reply":"2023-10-29T14:54:57.681832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dirpath, dirnames, filenames in os.walk(test_dir):\n  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:57.685119Z","iopub.execute_input":"2023-10-29T14:54:57.685407Z","iopub.status.idle":"2023-10-29T14:54:58.092625Z","shell.execute_reply.started":"2023-10-29T14:54:57.685383Z","shell.execute_reply":"2023-10-29T14:54:58.091499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def view_random_image(target_dir, target_class):\n  target_folder = target_dir+target_class\n  random_image = random.sample(os.listdir(target_folder), 1)\n  img = mpimg.imread(target_folder + \"/\" + random_image[0])\n  plt.imshow(img)\n  plt.title(target_class)\n  plt.axis(\"off\");\n  print(f\"Image shape: {img.shape}\")\n  return img","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:58.09388Z","iopub.execute_input":"2023-10-29T14:54:58.094191Z","iopub.status.idle":"2023-10-29T14:54:58.099891Z","shell.execute_reply.started":"2023-10-29T14:54:58.094165Z","shell.execute_reply":"2023-10-29T14:54:58.098917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = view_random_image(target_dir=test_dir,\n                        target_class=\"glioma\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:58.101143Z","iopub.execute_input":"2023-10-29T14:54:58.101421Z","iopub.status.idle":"2023-10-29T14:54:58.446272Z","shell.execute_reply.started":"2023-10-29T14:54:58.101397Z","shell.execute_reply":"2023-10-29T14:54:58.445238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 50\nfrom math import floor\nN_FOLDS = 5\nINIT_LR = 1e-3\nT_BS = 16\nV_BS = 16\ndecay_rate = 0.95\ndecay_step = 1\nIMAGE_SIZE = [224,224]","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:58.447651Z","iopub.execute_input":"2023-10-29T14:54:58.447955Z","iopub.status.idle":"2023-10-29T14:54:58.453282Z","shell.execute_reply.started":"2023-10-29T14:54:58.447929Z","shell.execute_reply":"2023-10-29T14:54:58.452421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow-addons\nimport tensorflow_addons as tfa\n\ndef augment_image(image, label):\n    # Apply augmentation transformations\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.1)\n    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n    image = tf.image.random_hue(image, max_delta=0.1)\n\n    # Apply the width and height shifts\n    width_shift = tf.random.uniform([], -0.2, 0.2) * tf.cast(tf.shape(image)[1], tf.float32)\n    height_shift = tf.random.uniform([], -0.2, 0.2) * tf.cast(tf.shape(image)[0], tf.float32)\n    image = tfa.image.translate(image, [width_shift, height_shift])\n\n    return image, label","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:54:58.454364Z","iopub.execute_input":"2023-10-29T14:54:58.454628Z","iopub.status.idle":"2023-10-29T14:55:30.334988Z","shell.execute_reply.started":"2023-10-29T14:54:58.454605Z","shell.execute_reply":"2023-10-29T14:55:30.333794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                 label_mode=\"categorical\",\n                                                                 batch_size=32,\n                                                                 image_size=IMAGE_SIZE)\n\ntest_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                                label_mode=\"categorical\",\n                                                                image_size=IMAGE_SIZE,\n                                                                shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:55:30.336536Z","iopub.execute_input":"2023-10-29T14:55:30.336871Z","iopub.status.idle":"2023-10-29T14:55:35.725676Z","shell.execute_reply.started":"2023-10-29T14:55:30.336843Z","shell.execute_reply":"2023-10-29T14:55:35.724928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply augmentation to the training dataset using the map function\ntrain_dataset_augmented = train_data.map(augment_image)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:55:35.729705Z","iopub.execute_input":"2023-10-29T14:55:35.730232Z","iopub.status.idle":"2023-10-29T14:55:37.133161Z","shell.execute_reply.started":"2023-10-29T14:55:35.730205Z","shell.execute_reply":"2023-10-29T14:55:37.132217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Combined_model():\n    # Input layer\n    input_layer = Input(shape=(224, 224, 3))\n\n    # Base VGG19 model as a feature extractor\n    baseModel = VGG19(weights=None, include_top=False, input_tensor=input_layer)\n\n    # Load the weights from the local file (specify the path)\n    baseModel.load_weights('/kaggle/input/vgg19-weight/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n    # Freeze the layers of the VGG19 model\n    for layer in baseModel.layers:\n        layer.trainable = False\n\n    x = baseModel.output\n\n    # LSTM layer\n    x = Reshape((49, 512))(x)\n    x = LSTM(512, activation=\"relu\", return_sequences=True, trainable=False)(x)\n    x = BatchNormalization()(x)\n\n    # FC layer\n    x = Flatten(name=\"flatten\")(x)\n\n    # fc1 layer\n    x = Dense(units=4096, activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    # fc2 layer\n    x = Dense(units=4096, activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    # Output layer\n    output = Dense(units=4, activation='softmax')(x)\n\n    model = Model(inputs=input_layer, outputs=output)\n    opt = Adam(lr=1e3)\n    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n    \n    return model\n\n# Create the model\nmodel = Combined_model()\n\n# Print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:55:37.134449Z","iopub.execute_input":"2023-10-29T14:55:37.134751Z","iopub.status.idle":"2023-10-29T14:55:38.538891Z","shell.execute_reply.started":"2023-10-29T14:55:37.134727Z","shell.execute_reply":"2023-10-29T14:55:38.537967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint = [ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy',mode='max',verbose=1,save_best_only=True,save_weights_only=True),\n             LearningRateScheduler(lambda epoch : INIT_LR * pow(decay_rate, floor(epoch / decay_step)))]\nearlystop = EarlyStopping(monitor='accuracy', min_delta=0, patience=15, verbose=1, mode='max')","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:55:38.540081Z","iopub.execute_input":"2023-10-29T14:55:38.540364Z","iopub.status.idle":"2023-10-29T14:55:38.546015Z","shell.execute_reply.started":"2023-10-29T14:55:38.540339Z","shell.execute_reply":"2023-10-29T14:55:38.545065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset_augmented,\n                    epochs=50,\n                    steps_per_epoch=len(train_dataset_augmented),\n                    validation_data = test_data,\n                    callbacks=[checkpoint])","metadata":{"execution":{"iopub.status.busy":"2023-10-29T14:55:38.547262Z","iopub.execute_input":"2023-10-29T14:55:38.54759Z","iopub.status.idle":"2023-10-29T15:33:32.803186Z","shell.execute_reply.started":"2023-10-29T14:55:38.54756Z","shell.execute_reply":"2023-10-29T15:33:32.802183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('/kaggle/working/best_model.h5')\n_, accuracy = model.evaluate(test_data)\nprint(f\"Validation accuracy: {round(accuracy * 100, 2)}%\")","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:32.804834Z","iopub.execute_input":"2023-10-29T15:33:32.80528Z","iopub.status.idle":"2023-10-29T15:33:40.487589Z","shell.execute_reply.started":"2023-10-29T15:33:32.805242Z","shell.execute_reply":"2023-10-29T15:33:40.486717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_probs = model.predict(test_data, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:40.488619Z","iopub.execute_input":"2023-10-29T15:33:40.488916Z","iopub.status.idle":"2023-10-29T15:33:47.561489Z","shell.execute_reply.started":"2023-10-29T15:33:40.488889Z","shell.execute_reply":"2023-10-29T15:33:47.560527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_classes = pred_probs.argmax(axis=1)\n\ny_labels = []\nfor images, labels in test_data.unbatch():\n  y_labels.append(labels.numpy().argmax())","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:47.562973Z","iopub.execute_input":"2023-10-29T15:33:47.563265Z","iopub.status.idle":"2023-10-29T15:33:48.811896Z","shell.execute_reply.started":"2023-10-29T15:33:47.56324Z","shell.execute_reply":"2023-10-29T15:33:48.810976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_names = ['Glioma', 'Meningioma', 'No Tumor','Pituitary']\nprint(classification_report(y_labels,\n                            pred_classes,\n                            target_names=target_names, digits=4))","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:48.813178Z","iopub.execute_input":"2023-10-29T15:33:48.813488Z","iopub.status.idle":"2023-10-29T15:33:48.830379Z","shell.execute_reply.started":"2023-10-29T15:33:48.813461Z","shell.execute_reply":"2023-10-29T15:33:48.829263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(y_labels,pred_classes)\n\nTP = cm[0, 0]\nTN = cm[1:, 1:].sum()\nFP = cm[0, 1:].sum()\nFN = cm[1:, 0].sum()\n\nPopulation = TN+FN+TP+FP\nspesificity = TN / (TN + FP)\nsensitivity = TP / (TP + FN)\n\nprint(\"True Positives:\", TP)\nprint(\"False Positives:\", FP)\nprint(\"True Negatives:\", TN)\nprint(\"False Negatives:\", FN)\nprint(\"Specificity:\", spesificity)\nprint(\"Sensitivity:\", sensitivity)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:48.831816Z","iopub.execute_input":"2023-10-29T15:33:48.832243Z","iopub.status.idle":"2023-10-29T15:33:48.844826Z","shell.execute_reply.started":"2023-10-29T15:33:48.832205Z","shell.execute_reply":"2023-10-29T15:33:48.843734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(20, 20), text_size=15, norm=False, savefig=False):\n\n  cm = confusion_matrix(y_true, y_pred)\n  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n  n_classes = cm.shape[0]\n\n  fig, ax = plt.subplots(figsize=figsize)\n  cax = ax.matshow(cm, cmap=plt.cm.Blues)\n  fig.colorbar(cax)\n\n  if classes:\n    labels = classes\n  else:\n    labels = np.arange(cm.shape[0])\n\n  ax.grid(False)\n\n  ax.set(title=\"Confusion Matrix\",\n         xlabel=\"Predicted label\",\n         ylabel=\"True label\",\n         xticks=np.arange(n_classes),\n         yticks=np.arange(n_classes),\n         xticklabels=labels,\n         yticklabels=labels)\n\n  ax.xaxis.set_label_position(\"bottom\")\n  ax.xaxis.tick_bottom()\n\n  plt.xticks(rotation=70, fontsize=text_size)\n  plt.yticks(fontsize=text_size)\n\n  threshold = (cm.max() + cm.min()) / 2.\n\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    if norm:\n      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)\n    else:\n      plt.text(j, i, f\"{cm[i, j]}\",\n              horizontalalignment=\"center\",\n              color=\"white\" if cm[i, j] > threshold else \"black\",\n              size=text_size)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:48.846048Z","iopub.execute_input":"2023-10-29T15:33:48.846349Z","iopub.status.idle":"2023-10-29T15:33:48.858853Z","shell.execute_reply.started":"2023-10-29T15:33:48.846323Z","shell.execute_reply":"2023-10-29T15:33:48.857695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"make_confusion_matrix(y_true=y_labels,\n                      y_pred=pred_classes,\n                      classes=target_names,\n                      figsize=(5, 5),\n                      text_size=12,\n                      norm=False,\n                      savefig=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:48.860248Z","iopub.execute_input":"2023-10-29T15:33:48.860965Z","iopub.status.idle":"2023-10-29T15:33:49.293542Z","shell.execute_reply.started":"2023-10-29T15:33:48.860931Z","shell.execute_reply":"2023-10-29T15:33:49.292635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(loss) + 1)\n\nplt.figure(figsize=(5.5, 4))\n\nplt.plot(epochs, loss, 'y', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and Validation Loss', fontsize=12)\nplt.xlabel('Epochs', fontsize=10)\nplt.ylabel('Loss', fontsize=10)\nplt.legend(fontsize=10)\n\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.grid(False)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:49.294693Z","iopub.execute_input":"2023-10-29T15:33:49.295018Z","iopub.status.idle":"2023-10-29T15:33:49.609368Z","shell.execute_reply.started":"2023-10-29T15:33:49.294991Z","shell.execute_reply":"2023-10-29T15:33:49.608419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = history.history['accuracy']\nval_loss = history.history['val_accuracy']\nepochs = range(1, len(loss) + 1)\n\nplt.figure(figsize=(5.5, 4))\n\nplt.plot(epochs, loss, 'y', label='Training acc')\nplt.plot(epochs, val_loss, 'r', label='Validation acc')\nplt.title('Training and Validation Loss', fontsize=12)\nplt.xlabel('Epochs', fontsize=10)\nplt.ylabel('Loss', fontsize=10)\nplt.legend(fontsize=10)\n\nplt.xticks(fontsize=10)\nplt.yticks(fontsize=10)\n\nplt.grid(False)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-10-29T15:33:49.610522Z","iopub.execute_input":"2023-10-29T15:33:49.610828Z","iopub.status.idle":"2023-10-29T15:33:49.890808Z","shell.execute_reply.started":"2023-10-29T15:33:49.610797Z","shell.execute_reply":"2023-10-29T15:33:49.889835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**My aim of doing this project is how we can apply hybrid model to sphere image classification which will be useful in our project and research field.If there is any query then you can mail[Aiyub Ali](http://) If you like this code, please upvote the it, Thank you!**","metadata":{}}]}